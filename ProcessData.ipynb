{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.interpolate as interpolate\n",
    "import pandas as pd\n",
    "from finderPeaksSignal import peakFinder\n",
    "\n",
    "\n",
    "#define landmarks \n",
    "\n",
    "WRIST = 0\n",
    "THUMB_CMC = 1\n",
    "THUMB_MCP = 2\n",
    "THUMB_IP = 3\n",
    "THUMB_TIP = 4\n",
    "INDEX_FINGER_MCP = 5\n",
    "INDEX_FINGER_PIP = 6\n",
    "INDEX_FINGER_DIP = 7\n",
    "INDEX_FINGER_TIP = 8\n",
    "MIDDLE_FINGER_MCP = 9\n",
    "MIDDLE_FINGER_PIP = 10\n",
    "MIDDLE_FINGER_DIP = 11\n",
    "MIDDLE_FINGER_TIP = 12\n",
    "RING_FINGER_MCP = 13\n",
    "RING_FINGER_PIP = 14\n",
    "RING_FINGER_DIP = 15\n",
    "RING_FINGER_TIP = 16\n",
    "PINKY_MCP = 17\n",
    "PINKY_PIP = 18\n",
    "PINKY_DIP = 19\n",
    "PINKY_TIP = 20\n",
    "\n",
    "\n",
    "def scaling(landmarks, scale='THUMBSIZE'):\n",
    "    \n",
    "    prevScale = []\n",
    "    newScale = []\n",
    "\n",
    "    for landmark in landmarks:\n",
    "\n",
    "        wrist, middle_finger_tip = landmark[WRIST], landmark[MIDDLE_FINGER_TIP]\n",
    "        dist = math.dist(wrist, middle_finger_tip)\n",
    "        prevScale.append(dist)\n",
    "\n",
    "        if scale == 'THUMBSIZE':\n",
    "            thumb_base, thumb_tip = landmark[THUMB_CMC], landmark[THUMB_TIP]\n",
    "            dist = math.dist(thumb_base, thumb_tip)\n",
    "            newScale.append(dist)\n",
    "        elif scale == 'INDEXSIZE':\n",
    "            index_base, index_tip = landmark[INDEX_FINGER_MCP], landmark[MIDDLE_FINGER_TIP]\n",
    "            dist = math.dist(index_base, index_tip)\n",
    "            newScale.append(dist)\n",
    "        else:\n",
    "            newScale.append(prevScale[-1])\n",
    "\n",
    "    #factor used to adjust scale\n",
    "    return np.max(prevScale)/np.max(newScale)\n",
    "\n",
    "\n",
    "def get_output(up_sample_signal):\n",
    "    distance, velocity, peaks, indexPositiveVelocity, indexNegativeVelocity = peakFinder(up_sample_signal, fs=60,\n",
    "                                                                                         minDistance=3,\n",
    "                                                                                         cutOffFrequency=7.5, prct=0.05)\n",
    "\n",
    "    amplitude = []\n",
    "    peakTime = []\n",
    "    rmsVelocity = []\n",
    "    speed = []\n",
    "    averageOpeningSpeed = []\n",
    "    averageClosingSpeed = []\n",
    "    cycleDuration = []\n",
    "\n",
    "    for idx, peak in enumerate(peaks):\n",
    "        # Height measures\n",
    "        x1 = peak['openingValleyIndex']\n",
    "        y1 = distance[peak['openingValleyIndex']]\n",
    "\n",
    "        x2 = peak['closingValleyIndex']\n",
    "        y2 = distance[peak['closingValleyIndex']]\n",
    "\n",
    "        x = peak['peakIndex']\n",
    "        y = distance[peak['peakIndex']]\n",
    "\n",
    "        f = interpolate.interp1d(np.array([x1, x2]), np.array([y1, y2]))\n",
    "\n",
    "        amplitude.append(y - f(x))\n",
    "\n",
    "        # Opening Velocity\n",
    "        rmsVelocity.append(np.sqrt(np.mean(velocity[peak['openingValleyIndex']:peak['closingValleyIndex']] ** 2)))\n",
    "\n",
    "\n",
    "        speed.append( (y - f(x)) / ((peak['closingValleyIndex']- peak['openingValleyIndex'])* (1 / 60)))\n",
    "        averageOpeningSpeed.append((y - f(x)) / ((peak['peakIndex'] - peak['openingValleyIndex']) * (1 / 60)))\n",
    "        averageClosingSpeed.append((y - f(x)) / ((peak['closingValleyIndex'] - peak['peakIndex']) * (1 / 60)))\n",
    "        cycleDuration.append((peak['closingValleyIndex'] - peak['openingValleyIndex'])* (1 / 60))\n",
    "        # timming\n",
    "        peakTime.append(peak['peakIndex'] * (1 / 60))\n",
    "\n",
    "    meanAmplitude = np.mean(amplitude)\n",
    "    stdAmplitude = np.std(amplitude)\n",
    "\n",
    "    meanSpeed = np.mean(speed)\n",
    "    stdSpeed = np.std(speed)\n",
    "\n",
    "    meanRMSVelocity = np.mean(rmsVelocity)\n",
    "    stdRMSVelocity = np.std(rmsVelocity)\n",
    "    meanAverageOpeningSpeed = np.mean(averageOpeningSpeed)\n",
    "    stdAverageOpeningSpeed = np.std(averageOpeningSpeed)\n",
    "    meanAverageClosingSpeed = np.mean(averageClosingSpeed)\n",
    "    stdAverageClosingSpeed = np.std(averageClosingSpeed)\n",
    "\n",
    "    meanCycleDuration = np.mean(cycleDuration)\n",
    "    stdCycleDuration = np.std(cycleDuration)\n",
    "    rangeCycleDuration = np.max(np.diff(peakTime)) - np.min(np.diff(peakTime))\n",
    "    rate = len(peaks) / (peaks[-1]['closingValleyIndex'] - peaks[0]['openingValleyIndex']) / (1 / 60)\n",
    "\n",
    "    earlyPeaks = peaks[:len(peaks) // 2]\n",
    "    latePeaks = peaks[-len(peaks) // 2:]\n",
    "    # amplitudeDecay = np.mean(distance[:len(peaks) // 3]) / np.mean(distance[-len(peaks) // 3:])\n",
    "    # velocityDecay = np.sqrt(\n",
    "    #     np.mean(velocity[earlyPeaks[0]['openingValleyIndex']:earlyPeaks[-1]['closingValleyIndex']] ** 2)) / np.sqrt(\n",
    "    #     np.mean(velocity[latePeaks[0]['openingValleyIndex']:latePeaks[-1]['closingValleyIndex']] ** 2))\n",
    "    rateDecay = (len(earlyPeaks) / ((earlyPeaks[-1]['closingValleyIndex'] - earlyPeaks[0]['openingValleyIndex']) / (1 / 60))) / (\n",
    "                        len(latePeaks) / (\n",
    "                        (latePeaks[-1]['closingValleyIndex'] - latePeaks[0]['openingValleyIndex']) / (1 / 60)))\n",
    "\n",
    "    amplitudeDecay = np.array(amplitude)[:len(amplitude)//2].mean() / np.array(amplitude)[len(amplitude)//2:].mean()\n",
    "    velocityDecay = np.array(rmsVelocity)[:len(rmsVelocity)//2].mean() / np.array(rmsVelocity)[len(rmsVelocity)//2:].mean()\n",
    "\n",
    "\n",
    "\n",
    "    cvAmplitude = stdAmplitude / meanAmplitude\n",
    "    cvSpeed = stdSpeed / meanSpeed\n",
    "    cvCycleDuration = stdCycleDuration / meanCycleDuration\n",
    "    cvRMSVelocity = stdRMSVelocity / meanRMSVelocity\n",
    "    cvAverageOpeningSpeed = stdAverageOpeningSpeed / meanAverageOpeningSpeed\n",
    "    cvAverageClosingSpeed = stdAverageClosingSpeed / meanAverageClosingSpeed\n",
    "\n",
    "    jsonFinal = {\n",
    "            \"MeanAmplitude\": meanAmplitude,\n",
    "            \"StdAmplitude\": stdAmplitude,\n",
    "            \"MeanSpeed\": meanSpeed,\n",
    "            \"StdSpeed\": stdSpeed,\n",
    "            \"MeanRMSVelocity\": meanRMSVelocity,\n",
    "            \"StdRMSVelocity\": stdRMSVelocity,\n",
    "            \"MeanOpeningSpeed\": meanAverageOpeningSpeed,\n",
    "            \"stdOpeningSpeed\": stdAverageOpeningSpeed,\n",
    "            \"meanClosingSpeed\": meanAverageClosingSpeed,\n",
    "            \"stdClosingSpeed\": stdAverageClosingSpeed,\n",
    "            \"meanCycleDuration\": meanCycleDuration,\n",
    "            \"stdCycleDuration\": stdCycleDuration,\n",
    "            \"rangeCycleDuration\": rangeCycleDuration,\n",
    "            \"rate\": rate,\n",
    "            \"amplitudeDecay\": amplitudeDecay,\n",
    "            \"velocityDecay\": velocityDecay,\n",
    "            \"rateDecay\": rateDecay,\n",
    "            \"cvAmplitude\": cvAmplitude,\n",
    "            \"cvCycleDuration\": cvCycleDuration,\n",
    "            \"cvSpeed\": cvSpeed,\n",
    "            \"cvRMSVelocity\" : cvRMSVelocity,\n",
    "            \"cvOpeningSpeed\": cvAverageOpeningSpeed,\n",
    "            \"cvClosingSpeed\": cvAverageClosingSpeed\n",
    "    }\n",
    "    return jsonFinal\n",
    "\n",
    "def get_fileName(file, outputFolder):\n",
    "\n",
    "    return os.path.join(outputFolder, os.path.splitext(file)[0] + '.csv')\n",
    "\n",
    "    \n",
    "\n",
    "def main():\n",
    "\n",
    "    inputFolder = 'data'\n",
    "    listFiles = os.listdir(inputFolder)\n",
    "\n",
    "    for file in listFiles:\n",
    "\n",
    "        f = open(os.path.join(inputFolder,file))\n",
    "        data = json.load(f)\n",
    "        f.close()\n",
    "\n",
    "        if 'allLandMarks' in data:\n",
    "            landMarks = data['allLandMarks']\n",
    "            linePlotData = data['linePlot']['data']\n",
    "            linePlotTime = data['linePlot']['time']\n",
    "        elif 'landMarks' in data:\n",
    "            landMarks = data['landMarks'][0]\n",
    "            linePlotData = data['linePlot']['data']\n",
    "            linePlotTime = data['linePlot']['time']\n",
    "        else:\n",
    "            landMarks = []\n",
    "            linePlotData = []\n",
    "            linePlotTime = []\n",
    "        \n",
    "        if len(landMarks)==0:\n",
    "            print(f'File {file} does not contain landmarks')\n",
    "            continue\n",
    "        else:\n",
    "            #compute scaling factor\n",
    "            scalingFactor = scaling(landMarks)\n",
    "            #scale signal and recompute parameters\n",
    "            outParameters = get_output(np.array(linePlotData)*scalingFactor)\n",
    "            #save to csv\n",
    "            cvsFilename = get_fileName(file, 'output')\n",
    "            pd.DataFrame.from_dict(data=outParameters, orient='index').to_csv(cvsFilename, header=False)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
